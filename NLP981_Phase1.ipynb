{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP981_Phase1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyeBright/NLP/blob/master/NLP981_Phase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tduc6QDQz1H",
        "colab_type": "text"
      },
      "source": [
        "# NLP981 Final Project - Phase #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0F0hIUs7oCS",
        "colab_type": "text"
      },
      "source": [
        "*   Instructor: Javad PourMostafa\n",
        "*   Teaching Assistant: Parsa Abbasi\n",
        "*   University of Guilan, 1st semester of 2019\n",
        "*   GitHub repository : *https://github.com/JoyeBright/NLP*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVC1mwiaOZMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUO9K1mKO2EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJiCXKiUNsUQ",
        "colab_type": "code",
        "outputId": "01e464e7-caf3-4a00-bc6e-762308193ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = \"Hello, world!\"\n",
        "print (nltk.word_tokenize(sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', ',', 'world', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aE9xQhhQ6XS",
        "colab_type": "text"
      },
      "source": [
        "It's the first phase of your final project for the *NLP981* course. The main idea behind this phase is to portray the develope side of *NLP*.\n",
        "\n",
        "You must code inside of this python notebook. I highly recommend you to use the *Google Colab* environment. \n",
        "\n",
        "If you have any questions, feel free to ask.\n",
        "You can use [*Quera*](https://quera.ir/course/4385/) platform for your general questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgS3aCY358dV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FG4cndz6DDq",
        "colab_type": "text"
      },
      "source": [
        "A category predictor is going to build at this phase of the project.\n",
        "\n",
        "The predictor gets a text as input and predicts a category for that.\n",
        "\n",
        "For this purpose, you need to :\n",
        "\n",
        "1.   Load the dataset\n",
        "2.   Preprocess the text data\n",
        "3.   Implement a word representation method to represent each text as a numeric vector\n",
        "4.   Implement a classification model and train that using the training set\n",
        "5.   Predict a category for each of validation data using implemented model\n",
        "6.   Measure your work using confusion matrix and some common metrics\n",
        "\n",
        "**Important Note:** You can use any library you want in sections 1 and 2. But everything in section 3-6 need to be coded purely.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0acil66KQ8A_",
        "colab_type": "text"
      },
      "source": [
        "## 1) Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haH1kfj3Q9tf",
        "colab_type": "text"
      },
      "source": [
        "The dataset you will use in this phase is called *Divar* that released by the *CafeBazaar* research team.\n",
        "\n",
        "It contains more than 900,000 posts of the *Divar* ads platform. We split this dataset into training, validation, and testing sets.\n",
        "\n",
        "The testing set is not accessible for you, and we use them to evaluate your work on the presentation day.\n",
        "\n",
        "You can download the dataset files (training and validation sets) directly from the following link :\n",
        "\n",
        "> *https://drive.google.com/open?id=1oj-fqpymjDr8QsOK-zQliiqXbVqakrFo*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdIRg1UBSOEi",
        "colab_type": "text"
      },
      "source": [
        "### 1.1) Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwCPJjaSQukm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the training and validation sets here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWHwVPkfS-OX",
        "colab_type": "text"
      },
      "source": [
        "### 1.2) Analyzing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlIKCffqU4AM",
        "colab_type": "text"
      },
      "source": [
        "Display the top 10 rows of the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw0EuzrFVIat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqfkJST6VMXt",
        "colab_type": "text"
      },
      "source": [
        "How many data (rows) stored in the training and validation sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkiaz92zVVpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_len = # Your code\n",
        "valid_len = # Your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aw0x_s3_b4U",
        "colab_type": "text"
      },
      "source": [
        "How many posts are in each category (First level categories)? (Based on training set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31PFgy46_ntw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUejNXljlZD1",
        "colab_type": "text"
      },
      "source": [
        "## 2) Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j1EilpbAi-W",
        "colab_type": "text"
      },
      "source": [
        "There are two kinds of text data in the dataset: *Title* and *Description*.\n",
        "You can use one or both of them as text inputs of your classification model. Choose a composition that gives you a higher measuring score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLT50bemjw3K",
        "colab_type": "text"
      },
      "source": [
        "You need to apply some preprocessing procedures on your text data first. We want at least **4** preprocessing step from you. It can be removing stop words, removing punctation, removing or replacing digits, stemming, lemmatizing, normalization, and so on.\n",
        "\n",
        "You can use the [*Stopwords Guilan NLP*](https://github.com/JoyeBright/stopwords_guilannlp) library to access a collection of Persian stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPQYAeEnlrcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(text):\n",
        "  # Your preprocessing steps\n",
        "  return cleared_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izN13hPulonI",
        "colab_type": "text"
      },
      "source": [
        "## 3) Word Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeC-rd4DMSUb",
        "colab_type": "text"
      },
      "source": [
        "As you know, classification models can't deal with strings directly, and you have to represent your texts in a numerical form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1rGMFJmqKwm",
        "colab_type": "text"
      },
      "source": [
        "### 3.1) Tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfPOmAF6qOF0",
        "colab_type": "text"
      },
      "source": [
        "You have to implement the tf-idf vectorization method from scratch in this step. \n",
        "\n",
        "Furthermore, a function must be implemented that gives a text input and return a tf-idf vectorized representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTZCMdqft4Ic",
        "colab_type": "text"
      },
      "source": [
        "$$\\text{tf-idf}(t, d) = \\text{tf}(t, d) \\times \\text{idf}(t)$$\n",
        "\n",
        "*tf* (term-frequency) is the count of occurrences of the word `t` in specific text `d`.\n",
        "\n",
        "*idf* (inverse document-frequency) is term that is inversely proportional to the number of texts with the given word. It can be calculated this way:\n",
        "$$\\text{idf}(t) = \\text{log}\\frac{1 + n_d}{1 + n_{d(t)}} + 1$$\n",
        "where $n_d$ is the whole number of texts and $n_{d(t)}$ is the number of texts with the word `t`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVwNZTGLqm20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yyUQ-_urWW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf(text):\n",
        "  # Your code\n",
        "  return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSDMXv46CWwm",
        "colab_type": "text"
      },
      "source": [
        "## 4) Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRpciSZZ-mb9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://cdn.lynda.com/course/578082/578082-637075371482276339-16x9.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk1EJq7B4JwX",
        "colab_type": "text"
      },
      "source": [
      